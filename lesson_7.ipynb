{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpQQpcyyWFMUX2r+7Hzq9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViRiver24/Lesson-7/blob/main/lesson_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yJDLztb7kLm",
        "outputId": "3c9b9ca2-358f-4fad-9957-d2412245fae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма даних: torch.Size([64, 1, 28, 28])\n",
            "Мінімальне значення пікселя: -1.0\n",
            "Максимальне значення пікселя: 1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Завантаження та попередня обробка даних\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                      # Перетворення в тензор\n",
        "    transforms.Normalize((0.5,), (0.5,))       # Нормалізація до діапазону [-1, 1]\n",
        "])\n",
        "\n",
        "# Завантаження набору даних MNIST\n",
        "mnist_dataset = datasets.MNIST(\n",
        "    root='./data',          # Де зберігати дані\n",
        "    train=True,             # Завантажити тренувальний набір\n",
        "    transform=transform,    # Застосувати трансформацію\n",
        "    download=True           # Завантажити, якщо немає локально\n",
        ")\n",
        "\n",
        "# Завантажувач даних (DataLoader)\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=mnist_dataset,\n",
        "    batch_size=64,          # Розмір батчу\n",
        "    shuffle=True            # Перемішування даних\n",
        ")\n",
        "\n",
        "# Перевірка\n",
        "images, labels = next(iter(data_loader))\n",
        "print(f\"Форма даних: {images.shape}\")\n",
        "print(f\"Мінімальне значення пікселя: {images.min()}\")\n",
        "print(f\"Максимальне значення пікселя: {images.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Архітектура генератора\n",
        "        self.fc1 = nn.Linear(z_dim, 256)  # Перший Dense шар\n",
        "        self.fc2 = nn.Linear(256, 512)    # Другий Dense шар\n",
        "        self.fc3 = nn.Linear(512, 1024)   # Третій Dense шар\n",
        "        self.fc4 = nn.Linear(1024, 28*28) # Вихідний Dense шар, розмір зображення 28x28\n",
        "\n",
        "        # Функції активації\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Пропуск через шари з активаціями\n",
        "        x = self.relu(self.fc1(z))   # Шар 1\n",
        "        x = self.relu(self.fc2(x))   # Шар 2\n",
        "        x = self.relu(self.fc3(x))   # Шар 3\n",
        "        x = self.fc4(x)              # Вихідний шар\n",
        "\n",
        "        # Перетворення в діапазон [-1, 1] за допомогою Tanh\n",
        "        x = self.tanh(x)\n",
        "\n",
        "        # Перетворення в зображення 28x28\n",
        "        return x.view(-1, 1, 28, 28)\n",
        "\n",
        "# Ініціалізація генератора\n",
        "z_dim = 100  # Розмір вхідного вектора шуму\n",
        "generator = Generator(z_dim)\n",
        "\n",
        "# Перевірка розміру вихідного зображення\n",
        "z = torch.randn(64, z_dim)  # Приклад випадкового шуму\n",
        "generated_images = generator(z)\n",
        "\n",
        "print(f\"Форма зображень: {generated_images.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffbX8Hl88det",
        "outputId": "e865ddf6-b9a1-4de3-cb2c-b0cf17d23170"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма зображень: torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Архітектура дискримінатора\n",
        "        self.fc1 = nn.Linear(28*28, 1024)   # Перший Dense шар\n",
        "        self.fc2 = nn.Linear(1024, 512)     # Другий Dense шар\n",
        "        self.fc3 = nn.Linear(512, 256)      # Третій Dense шар\n",
        "        self.fc4 = nn.Linear(256, 1)        # Вихідний шар (1 вихід для класифікації)\n",
        "\n",
        "        # Функції активації\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2) # LeakyReLU з параметром негативного нахилу 0.2\n",
        "        self.sigmoid = nn.Sigmoid()         # Sigmoid для виведення ймовірності\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Перетворення зображення в одномірний вектор\n",
        "        x = x.view(-1, 28*28)  # Перетворення з 28x28 в 784 елементи\n",
        "        x = self.leaky_relu(self.fc1(x))  # Шар 1\n",
        "        x = self.leaky_relu(self.fc2(x))  # Шар 2\n",
        "        x = self.leaky_relu(self.fc3(x))  # Шар 3\n",
        "        x = self.fc4(x)                   # Вихідний шар\n",
        "\n",
        "        # Використовуємо sigmoid для отримання ймовірності\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Ініціалізація дискримінатора\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Перевірка розміру вихідного результату\n",
        "sample_image = torch.randn(64, 1, 28, 28)  # Приклад випадкових зображень (batch_size=64)\n",
        "output = discriminator(sample_image)\n",
        "\n",
        "print(f\"Форма виходу: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqdANE2l8uJl",
        "outputId": "b52577c6-057d-4870-dcb1-cd97e7a4ec4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма виходу: torch.Size([64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Функція втрат: binary cross-entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Ініціалізація оптимізаторів для генератора та дискримінатора\n",
        "lr = 0.0002  # Коефіцієнт навчання\n",
        "\n",
        "# Оптимізатор для генератора\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Оптимізатор для дискримінатора\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Перевірка ініціалізації оптимізаторів та функції втрат\n",
        "print(\"Оптимізатор для генератора:\", optimizer_g)\n",
        "print(\"Оптимізатор для дискримінатора:\", optimizer_d)\n",
        "print(\"Функція втрат:\", criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbpjg_NC89Lr",
        "outputId": "5ae82388-0c27-4bff-d4b0-659339a766cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оптимізатор для генератора: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0002\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Оптимізатор для дискримінатора: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.5, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0002\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Функція втрат: BCELoss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Перевірка наявності GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Завантаження MNIST даних\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(mnist_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Ініціалізація моделей генератора та дискримінатора\n",
        "z_dim = 100\n",
        "generator = Generator(z_dim).to(device)  # Переміщуємо генератор на GPU або CPU\n",
        "discriminator = Discriminator().to(device)  # Переміщуємо дискримінатор на GPU або CPU\n",
        "\n",
        "# Функція втрат та оптимізатори\n",
        "criterion = nn.BCELoss()\n",
        "lr = 0.0002\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Функція для збереження зображень\n",
        "def save_generated_images(epoch, fixed_noise):\n",
        "    with torch.no_grad():\n",
        "        generated_images = generator(fixed_noise)\n",
        "        generated_images = generated_images.detach().cpu().numpy()\n",
        "        generated_images = (generated_images + 1) / 2  # Перетворення в діапазон [0, 1]\n",
        "\n",
        "        fig, axes = plt.subplots(1, 8, figsize=(12, 12))\n",
        "        for i, ax in enumerate(axes):\n",
        "            ax.imshow(np.transpose(generated_images[i], (1, 2, 0)).squeeze(), cmap='gray')\n",
        "            ax.axis('off')\n",
        "        plt.savefig(f'generated_images_epoch_{epoch}.png')\n",
        "        plt.close()\n",
        "\n",
        "# Навчання GAN\n",
        "num_epochs = 50\n",
        "fixed_noise = torch.randn(8, z_dim, device=device)  # Фіксований шум на тому ж пристрої\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for real_images, _ in data_loader:\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Переміщення реальних зображень та міток на правильний пристрій\n",
        "        real_images = real_images.to(device)\n",
        "        real_labels = torch.ones(batch_size, 1, device=device)\n",
        "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        # --- Навчання дискримінатора ---\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Прогноз дискримінатора на реальних зображеннях\n",
        "        output_real = discriminator(real_images)\n",
        "        d_loss_real = criterion(output_real, real_labels)\n",
        "\n",
        "        # Генерація фейкових зображень\n",
        "        noise = torch.randn(batch_size, z_dim, device=device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Прогноз дискримінатора на згенерованих зображеннях\n",
        "        output_fake = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(output_fake, fake_labels)\n",
        "\n",
        "        # Всього втрат для дискримінатора\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # --- Навчання генератора ---\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Прогноз дискримінатора на згенерованих зображеннях (генератор намагається обдурити дискримінатор)\n",
        "        output_fake_for_g = discriminator(fake_images)\n",
        "        g_loss = criterion(output_fake_for_g, real_labels)  # Мітка 1 для генератора\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
        "\n",
        "    # Збереження зображень після кожної епохи\n",
        "    save_generated_images(epoch + 1, fixed_noise)\n",
        "\n",
        "print(\"Навчання завершено!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtoMV9N--LH7",
        "outputId": "6b835b97-1c41-4ea3-95f7-f3d1ab04bf83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], D Loss: 0.4901524782180786, G Loss: 1.808892011642456\n",
            "Epoch [2/50], D Loss: 0.2605823278427124, G Loss: 3.7215170860290527\n",
            "Epoch [3/50], D Loss: 0.1853657066822052, G Loss: 3.8130784034729004\n",
            "Epoch [4/50], D Loss: 0.1945807933807373, G Loss: 3.834359645843506\n",
            "Epoch [5/50], D Loss: 0.100370392203331, G Loss: 4.061067581176758\n",
            "Epoch [6/50], D Loss: 0.5055583119392395, G Loss: 5.376664638519287\n",
            "Epoch [7/50], D Loss: 0.5776491165161133, G Loss: 2.5038490295410156\n",
            "Epoch [8/50], D Loss: 0.7711988091468811, G Loss: 1.6287810802459717\n",
            "Epoch [9/50], D Loss: 0.9833308458328247, G Loss: 1.2963560819625854\n",
            "Epoch [10/50], D Loss: 0.6708999872207642, G Loss: 1.6636345386505127\n",
            "Epoch [11/50], D Loss: 0.7493727207183838, G Loss: 1.5428266525268555\n",
            "Epoch [12/50], D Loss: 0.6954547166824341, G Loss: 1.685975193977356\n",
            "Epoch [13/50], D Loss: 0.757044792175293, G Loss: 2.274993896484375\n",
            "Epoch [14/50], D Loss: 0.7424869537353516, G Loss: 1.778397798538208\n",
            "Epoch [15/50], D Loss: 0.9466207027435303, G Loss: 1.6872024536132812\n",
            "Epoch [16/50], D Loss: 0.8342639207839966, G Loss: 1.3333017826080322\n",
            "Epoch [17/50], D Loss: 1.473465919494629, G Loss: 0.5818939805030823\n",
            "Epoch [18/50], D Loss: 0.8775928616523743, G Loss: 1.346529483795166\n",
            "Epoch [19/50], D Loss: 1.4065377712249756, G Loss: 1.0360928773880005\n",
            "Epoch [20/50], D Loss: 1.0618245601654053, G Loss: 1.4606101512908936\n",
            "Epoch [21/50], D Loss: 0.94929438829422, G Loss: 1.2866322994232178\n",
            "Epoch [22/50], D Loss: 0.8731011748313904, G Loss: 1.9730448722839355\n",
            "Epoch [23/50], D Loss: 0.8037501573562622, G Loss: 1.9778305292129517\n",
            "Epoch [24/50], D Loss: 1.0801780223846436, G Loss: 1.3797658681869507\n",
            "Epoch [25/50], D Loss: 1.2117480039596558, G Loss: 0.8193974494934082\n",
            "Epoch [26/50], D Loss: 0.9451581239700317, G Loss: 2.0509157180786133\n",
            "Epoch [27/50], D Loss: 1.1552233695983887, G Loss: 1.869873285293579\n",
            "Epoch [28/50], D Loss: 1.2829127311706543, G Loss: 2.1485846042633057\n",
            "Epoch [29/50], D Loss: 1.0146887302398682, G Loss: 1.4739323854446411\n",
            "Epoch [30/50], D Loss: 0.9723598957061768, G Loss: 1.1370105743408203\n",
            "Epoch [31/50], D Loss: 0.9225256443023682, G Loss: 1.2888743877410889\n",
            "Epoch [32/50], D Loss: 0.8583940267562866, G Loss: 1.8385162353515625\n",
            "Epoch [33/50], D Loss: 0.9280591011047363, G Loss: 1.7785509824752808\n",
            "Epoch [34/50], D Loss: 0.9565982818603516, G Loss: 1.597219467163086\n",
            "Epoch [35/50], D Loss: 1.099937081336975, G Loss: 1.3769724369049072\n",
            "Epoch [36/50], D Loss: 0.9767782688140869, G Loss: 1.448880910873413\n",
            "Epoch [37/50], D Loss: 0.9647007584571838, G Loss: 1.5982567071914673\n",
            "Epoch [38/50], D Loss: 0.876073956489563, G Loss: 1.8857817649841309\n",
            "Epoch [39/50], D Loss: 0.9978295564651489, G Loss: 1.9637527465820312\n",
            "Epoch [40/50], D Loss: 0.8341907262802124, G Loss: 1.9654688835144043\n",
            "Epoch [41/50], D Loss: 0.7724828124046326, G Loss: 1.2289202213287354\n",
            "Epoch [42/50], D Loss: 1.1130132675170898, G Loss: 1.5371568202972412\n",
            "Epoch [43/50], D Loss: 1.0259287357330322, G Loss: 2.1115493774414062\n",
            "Epoch [44/50], D Loss: 0.9679784774780273, G Loss: 1.898174524307251\n",
            "Epoch [45/50], D Loss: 0.9237977266311646, G Loss: 1.7518916130065918\n",
            "Epoch [46/50], D Loss: 0.8883262276649475, G Loss: 1.5688368082046509\n",
            "Epoch [47/50], D Loss: 0.9004300832748413, G Loss: 2.087556838989258\n",
            "Epoch [48/50], D Loss: 0.7985122203826904, G Loss: 2.069861650466919\n",
            "Epoch [49/50], D Loss: 0.9201717972755432, G Loss: 1.4944928884506226\n",
            "Epoch [50/50], D Loss: 1.141201376914978, G Loss: 1.4481258392333984\n",
            "Навчання завершено!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Функція для збереження та візуалізації зображень\n",
        "def save_generated_images(epoch, fixed_noise, generator, device, output_dir=\"generated_images\"):\n",
        "    with torch.no_grad():\n",
        "        # Генерація зображень з фіксованим шумом\n",
        "        generated_images = generator(fixed_noise).detach().cpu()\n",
        "        generated_images = (generated_images + 1) / 2  # Перетворення в діапазон [0, 1]\n",
        "\n",
        "        # Створення директорії для збереження, якщо її ще немає\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Збереження зображень\n",
        "        fig, axes = plt.subplots(1, 8, figsize=(12, 12))\n",
        "        for i, ax in enumerate(axes):\n",
        "            ax.imshow(np.transpose(generated_images[i], (1, 2, 0)).squeeze(), cmap='gray')\n",
        "            ax.axis('off')\n",
        "        plt.savefig(f'{output_dir}/generated_images_epoch_{epoch}.png')\n",
        "        plt.close()\n",
        "\n",
        "# Збереження найкращої моделі генератора\n",
        "def save_best_model(generator, epoch, g_loss, best_g_loss, model_dir=\"models\"):\n",
        "    if g_loss < best_g_loss:\n",
        "        # Оновлення найкращої втрати та збереження моделі\n",
        "        best_g_loss = g_loss\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "        torch.save(generator.state_dict(), f'{model_dir}/best_generator.pth')\n",
        "        print(f\"Збережено найкращу модель генератора на епосі {epoch}\")\n",
        "    return best_g_loss\n",
        "\n",
        "# Навчання GAN з візуалізацією та збереженням моделі\n",
        "num_epochs = 50\n",
        "fixed_noise = torch.randn(8, z_dim, device=device)  # Фіксований шум для візуалізації\n",
        "best_g_loss = float('inf')  # Ініціалізація найкращої втрати для генератора\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for real_images, _ in data_loader:\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Переміщення даних на пристрій\n",
        "        real_images = real_images.to(device)\n",
        "        real_labels = torch.ones(batch_size, 1, device=device)\n",
        "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        # --- Навчання дискримінатора ---\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Прогноз на реальних зображеннях\n",
        "        output_real = discriminator(real_images)\n",
        "        d_loss_real = criterion(output_real, real_labels)\n",
        "\n",
        "        # Генерація фейкових зображень\n",
        "        noise = torch.randn(batch_size, z_dim, device=device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Прогноз на згенерованих зображеннях\n",
        "        output_fake = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(output_fake, fake_labels)\n",
        "\n",
        "        # Загальні втрати для дискримінатора\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # --- Навчання генератора ---\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Прогноз для генератора (ми хочемо, щоб дискримінатор приймав фейкові зображення за реальні)\n",
        "        output_fake_for_g = discriminator(fake_images)\n",
        "        g_loss = criterion(output_fake_for_g, real_labels)  # Мітка 1 для генератора\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
        "\n",
        "    # Збереження зображень після кожної епохи\n",
        "    if (epoch + 1) % 5 == 0:  # Збереження зображень кожні 5 епох\n",
        "        save_generated_images(epoch + 1, fixed_noise, generator, device)\n",
        "\n",
        "    # Оновлення найкращої моделі генератора\n",
        "    best_g_loss = save_best_model(generator, epoch + 1, g_loss.item(), best_g_loss)\n",
        "\n",
        "print(\"Навчання завершено!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPeLPAlMB2L8",
        "outputId": "c991059c-5462-4168-8ce6-a235743fda24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], D Loss: 0.9642716646194458, G Loss: 1.5269559621810913\n",
            "Збережено найкращу модель генератора на епосі 1\n",
            "Epoch [2/50], D Loss: 0.8828217387199402, G Loss: 2.5503602027893066\n",
            "Epoch [3/50], D Loss: 1.0358697175979614, G Loss: 1.6038002967834473\n",
            "Epoch [4/50], D Loss: 1.0999438762664795, G Loss: 2.5469884872436523\n",
            "Epoch [5/50], D Loss: 0.8785251379013062, G Loss: 2.037558078765869\n",
            "Epoch [6/50], D Loss: 0.9338296055793762, G Loss: 2.1992149353027344\n",
            "Epoch [7/50], D Loss: 1.0180569887161255, G Loss: 1.1594810485839844\n",
            "Збережено найкращу модель генератора на епосі 7\n",
            "Epoch [8/50], D Loss: 1.0071702003479004, G Loss: 1.853919506072998\n",
            "Epoch [9/50], D Loss: 0.9061351418495178, G Loss: 1.9339609146118164\n",
            "Epoch [10/50], D Loss: 0.9154525399208069, G Loss: 1.9707765579223633\n",
            "Epoch [11/50], D Loss: 0.9796486496925354, G Loss: 1.4361650943756104\n",
            "Epoch [12/50], D Loss: 1.4164085388183594, G Loss: 1.022302269935608\n",
            "Збережено найкращу модель генератора на епосі 12\n",
            "Epoch [13/50], D Loss: 0.9881643056869507, G Loss: 1.948348045349121\n",
            "Epoch [14/50], D Loss: 0.7238607406616211, G Loss: 2.1840429306030273\n",
            "Epoch [15/50], D Loss: 1.1524076461791992, G Loss: 2.358597755432129\n",
            "Epoch [16/50], D Loss: 0.881400465965271, G Loss: 2.2155487537384033\n",
            "Epoch [17/50], D Loss: 0.8972585201263428, G Loss: 2.2762372493743896\n",
            "Epoch [18/50], D Loss: 1.0862724781036377, G Loss: 1.7878355979919434\n",
            "Epoch [19/50], D Loss: 0.8861830830574036, G Loss: 2.713593006134033\n",
            "Epoch [20/50], D Loss: 1.0540331602096558, G Loss: 2.256094455718994\n",
            "Epoch [21/50], D Loss: 0.8580762147903442, G Loss: 1.7922942638397217\n",
            "Epoch [22/50], D Loss: 0.9754116535186768, G Loss: 1.7631077766418457\n",
            "Epoch [23/50], D Loss: 1.1392817497253418, G Loss: 2.038470506668091\n",
            "Epoch [24/50], D Loss: 0.9536771774291992, G Loss: 1.6740305423736572\n",
            "Epoch [25/50], D Loss: 0.9900815486907959, G Loss: 1.6703619956970215\n",
            "Epoch [26/50], D Loss: 1.262850284576416, G Loss: 2.4926917552948\n",
            "Epoch [27/50], D Loss: 0.7875462770462036, G Loss: 1.8101046085357666\n",
            "Epoch [28/50], D Loss: 0.9346948862075806, G Loss: 2.289517402648926\n",
            "Epoch [29/50], D Loss: 0.9561326503753662, G Loss: 1.2345261573791504\n",
            "Epoch [30/50], D Loss: 1.1418932676315308, G Loss: 1.8578482866287231\n",
            "Epoch [31/50], D Loss: 0.9457675218582153, G Loss: 1.9478950500488281\n",
            "Epoch [32/50], D Loss: 1.0506248474121094, G Loss: 1.7244949340820312\n",
            "Epoch [33/50], D Loss: 0.9068368673324585, G Loss: 1.489374041557312\n",
            "Epoch [34/50], D Loss: 0.8844723701477051, G Loss: 2.0578126907348633\n",
            "Epoch [35/50], D Loss: 0.9150668978691101, G Loss: 1.7571699619293213\n",
            "Epoch [36/50], D Loss: 0.5898510217666626, G Loss: 2.213325023651123\n",
            "Epoch [37/50], D Loss: 1.0372897386550903, G Loss: 2.1242332458496094\n",
            "Epoch [38/50], D Loss: 0.8507957458496094, G Loss: 1.8787171840667725\n",
            "Epoch [39/50], D Loss: 0.8266328573226929, G Loss: 1.6415297985076904\n",
            "Epoch [40/50], D Loss: 0.8495135307312012, G Loss: 1.5161296129226685\n",
            "Epoch [41/50], D Loss: 1.0573759078979492, G Loss: 1.9471713304519653\n",
            "Epoch [42/50], D Loss: 1.0446938276290894, G Loss: 1.4685344696044922\n",
            "Epoch [43/50], D Loss: 1.053646445274353, G Loss: 1.676560401916504\n",
            "Epoch [44/50], D Loss: 0.9279148578643799, G Loss: 1.847489833831787\n",
            "Epoch [45/50], D Loss: 1.0501679182052612, G Loss: 1.6255720853805542\n",
            "Epoch [46/50], D Loss: 0.8722474575042725, G Loss: 1.8248438835144043\n",
            "Epoch [47/50], D Loss: 0.8826333284378052, G Loss: 2.2504873275756836\n",
            "Epoch [48/50], D Loss: 0.9761372208595276, G Loss: 2.2789711952209473\n",
            "Epoch [49/50], D Loss: 0.7761939764022827, G Loss: 1.499342918395996\n",
            "Epoch [50/50], D Loss: 0.9795239567756653, G Loss: 1.5259833335876465\n",
            "Навчання завершено!\n"
          ]
        }
      ]
    }
  ]
}